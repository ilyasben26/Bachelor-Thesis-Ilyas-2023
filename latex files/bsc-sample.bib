@inproceedings{Glaessgen2012TheDT,
  title={The Digital Twin Paradigm for Future NASA and U.S. Air Force Vehicles},
  author={Edward H. Glaessgen and Doane Stargel},
  year={2012}
}

@ARTICLE{9103025,

  author={Fuller, Aidan and Fan, Zhong and Day, Charles and Barlow, Chris},

  journal={IEEE Access}, 

  title={Digital Twin: Enabling Technologies, Challenges and Open Research}, 

  year={2020},

  volume={8},

  number={},

  pages={108952-108971},

  doi={10.1109/ACCESS.2020.2998358}
}


@INPROCEEDINGS{9540108,

  author={Gao, Yan and Qian, Shuyue and Li, Zihan and Wang, Ping and Wang, Feiyue and He, Qing},

  booktitle={2021 IEEE 1st International Conference on Digital Twins and Parallel Intelligence (DTPI)}, 

  title={Digital Twin and Its Application in Transportation Infrastructure}, 

  year={2021},

  volume={},

  number={},

  pages={298-301},

  doi={10.1109/DTPI52967.2021.9540108}
}


@inproceedings{inproceedings,
author = {Ashfaq, Niaz and Muhammad Usman, Shoukat and Jia, Yanbing and Khan, Samiullah and Niaz, Fahim and Raza, Muhammad},
year = {2021},
month = {10},
pages = {1-7},
title = {Autonomous Driving Test Method Based on Digital Twin: A Survey},
doi = {10.1109/ICECube53880.2021.9628341}
}

@inbook{inbook,
author = {Guarino, Nicola and Oberle, Daniel and Staab, Steffen},
year = {2009},
month = {05},
pages = {1-17},
title = {What Is an Ontology?},
journal = {Handbook on Ontologies},
doi = {10.1007/978-3-540-92673-3_0}
}

@online{whatontology,
author = {Natalya F. Noy  and Deborah L. McGuinness},
title = {Ontology Development 101: A Guide to Creating Your First Ontology},
url = {https://protege.stanford.edu/publications/ontology_development/ontology101-noy-mcguinness.html}

}

@online{nlp,
author = {Dominique Estival, Chris Nowak and Andrew Zschorn},
title = {Towards Ontology-Based Natural Language Processing},
url = {https://aclanthology.org/W04-0609.pdf}

}

@inproceedings{biomed,
author = {Queralt-Rosinach, Núria and Bernabé, César Henrique and Long, Qinqin and Kaliyaperumal, Rajaram and Roos, Marco},
year = {2022},
month = {01},
pages = {},
title = {LUMC Clinical Ontology for Biomedical Research}
}

@online{azure,
url = {https://learn.microsoft.com/en-us/azure/digital-twins/concepts-ontologies}
}

@article{machines10100861,
	abstract = {The rapid emerging technologies in various fields permitted the creation of simulation tools. These tools are designed to replicate physical systems in order to provide faster, cheaper and more detailed illustrative analysis of the physical system. In this regard, the concept of digital twins has been introduced to generally define these simulation tools. In fact, and according to the creator of the digital twin term Micheal Grieves, a digital twin is defined as a physical system, a digital replica of the physical system and information flow between the former parts. This definition is simple and generic for describing digital twins and yet, holistic. This broad definition creates a challenge for developers who target the development of such applications. Therefore, this paper presents a paradigm for architecting digital twins for manufacturing processes. The approach is inspired by the definitions of the ISA95 standard and the onion concept of computer applications to create multi-layer and multi-level concepts. Furthermore, and to satisfy the different required features by industries, the approach considers a multi-perspective concept that allows the separation of the digital twin views based on functionality. This paradigm aims at providing a modular, scalable, reusable, interoperable and composable approach for developing digital twins. Then, an implementation of the approach has been introduced using an ontology-based system and the IEC61499 standard. This implementation has been demonstrated on a discrete manufacturing assembly line.},
	article-number = {861},
	author = {Mohammed, Wael M. and Haber, Rodolfo E. and Martinez Lastra, Jose L.},
	doi = {10.3390/machines10100861},
	issn = {2075-1702},
	journal = {Machines},
	number = {10},
	title = {Ontology-Driven Guidelines for Architecting Digital Twins in Factory Automation Applications},
	url = {https://www.mdpi.com/2075-1702/10/10/861},
	volume = {10},
	year = {2022},
	bdsk-url-1 = {https://www.mdpi.com/2075-1702/10/10/861},
	bdsk-url-2 = {https://doi.org/10.3390/machines10100861}
}
	

@inproceedings{10.1007/978-3-642-12297-2_34,
	abstract = {We study the problem of classifying images into a given, pre-determined taxonomy. The task can be elegantly translated into the structured learning framework. Structured learning, however, is known for its memory consuming and slow training processes. The contribution of our paper is twofold: Firstly, we propose an efficient decomposition of the structured learning approach into an equivalent ensemble of local support vector machines (SVMs) which can be trained with standard techniques. Secondly, we combine the local SVMs to a global model by re-incorporating the taxonomy into the training process. Our empirical results on Caltech256 and VOC2006 data show that our local-global SVM effectively exploits the structure of the taxonomy and outperforms multi-class classification approaches.},
	address = {Berlin, Heidelberg},
	author = {Binder, Alexander and Kawanabe, Motoaki and Brefeld, Ulf},
	booktitle = {Computer Vision -- ACCV 2009},
	editor = {Zha, Hongbin and Taniguchi, Rin-ichiro and Maybank, Stephen},
	isbn = {978-3-642-12297-2},
	pages = {351--362},
	publisher = {Springer Berlin Heidelberg},
	title = {Efficient Classification of Images with Taxonomies},
	year = {2010}
}
	
@article{qi2016pointnet,
  title={PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation},
  author={Qi, Charles R and Su, Hao and Mo, Kaichun and Guibas, Leonidas J},
  journal={arXiv preprint arXiv:1612.00593},
  year={2016}
}



@article{3dlitreview,
	abstract = {In this paper, we present a systematic literature review concerning 3D object recognition and classification. We cover articles published between 2006 and 2016 available in three scientific databases (ScienceDirect, IEEE Xplore and ACM), using the methodology for systematic review proposed by Kitchenham. Based on this methodology, we used tags and exclusion criteria to select papers about the topic under study. After the works selection, we applied a categorization process aiming to group similar object representation types, analyzing the steps applied for object recognition, the tests and evaluation performed and the databases used. Lastly, we compressed all the obtained information in a general overview and presented future prospects for the area.},
	author = {Carvalho, L. E. and von Wangenheim, A.},
	date = {2019/11/01},
	date-added = {2023-03-13 15:59:53 +0100},
	date-modified = {2023-03-13 15:59:53 +0100},
	doi = {10.1007/s10044-019-00804-4},
	id = {Carvalho2019},
	isbn = {1433-755X},
	journal = {Pattern Analysis and Applications},
	number = {4},
	pages = {1243--1292},
	title = {3D object recognition and classification: a systematic literature review},
	url = {https://doi.org/10.1007/s10044-019-00804-4},
	volume = {22},
	year = {2019},
	bdsk-url-1 = {https://doi.org/10.1007/s10044-019-00804-4}
}
	
	

@inproceedings{10.1007/978-981-16-5348-3_36,
	abstract = {Adjailia, FouziaRasamoelina, Andrinandrasana DavidSincak, PeterA crucial component of artificial intelligence and image processing is 3D object classification. It helps to achieve significant and complex changes in performance through feature representation and processing of the images. Feature extraction plays a significant step in machine learning as it facilitates the feeding of insightful and non-redundant values to the machine learning algorithms. In this paper, we will present a framework to construct a 3D object classification system using several machine learning classifiers, and features were extracted using a local object structure descriptor called the 3D Voxel histogram of oriented gradient. We say that incorporating 3D classification tasks is a powerful strategy. This means enhancing performance, precision, and efficiency of learning. The system contributed to increase efficiency and produced impressive results of 88 and 89{\%} accuracy using Support vector machine and extreme Gradient Boosting, respectively. The results will be discussed and evaluated.},
	address = {Singapore},
	author = {Adjailia, Fouzia and Rasamoelina, Andrinandrasana David and Sincak, Peter},
	booktitle = {Proceedings of International Conference on Data Science and Applications},
	editor = {Saraswat, Mukesh and Roy, Sarbani and Chowdhury, Chandreyee and Gandomi, Amir H.},
	isbn = {978-981-16-5348-3},
	pages = {459--470},
	publisher = {Springer Singapore},
	title = {3D Object Classification Using HOG3D},
	year = {2022}
}

@misc{https://doi.org/10.48550/arxiv.1912.11606,
  doi = {10.48550/ARXIV.1912.11606},
  
  url = {https://arxiv.org/abs/1912.11606},
  
  author = {Cao, Hui and Du, Haikuan and Zhang, Siyu and Cai, Shen},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {InSphereNet: a Concise Representation and Classification Method for 3D Object},
  
  publisher = {arXiv},
  
  year = {2019},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{https://doi.org/10.48550/arxiv.2106.15778,
  doi = {10.48550/ARXIV.2106.15778},
  
  url = {https://arxiv.org/abs/2106.15778},
  
  author = {Qiu, Wenming Tang Guoping},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Graphics (cs.GR), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Dense Graph Convolutional Neural Networks on 3D Meshes for 3D Object Segmentation and Classification},
  
  publisher = {arXiv},
  
  year = {2021},
  
  copyright = {Creative Commons Attribution 4.0 International}
}

@inproceedings{feng2019meshnet,
  title={Meshnet: Mesh neural network for 3d shape representation},
  author={Feng, Yutong and Feng, Yifan and You, Haoxuan and Zhao, Xibin and Gao, Yue},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={33},
  number={01},
  pages={8279--8286},
  year={2019}
}

@misc{https://doi.org/10.48550/arxiv.1505.00880,
  doi = {10.48550/ARXIV.1505.00880},
  
  url = {https://arxiv.org/abs/1505.00880},
  
  author = {Su, Hang and Maji, Subhransu and Kalogerakis, Evangelos and Learned-Miller, Erik},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Graphics (cs.GR), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Multi-view Convolutional Neural Networks for 3D Shape Recognition},
  
  publisher = {arXiv},
  
  year = {2015},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@online{scopus,
		title = {Scopus},
		url = {https://www.scopus.com/}
}

@online{BingAI,
title = {Reinventing search with a new AI-powered Microsoft Bing and Edge, your copilot for the web},
url = {https://blogs.microsoft.com/blog/2023/02/07/reinventing-search-with-a-new-ai-powered-microsoft-bing-and-edge-your-copilot-for-the-web/}
}


@misc{elicit,
  author = {{Ought}},
  title = {Elicit: The AI Research Assistant},
  url = {https://elicit.org},
  year = {2023},
  date = {2023-02-22},
}
@article{protege,
    author = {Musen, Mark A.},
    title = {The Prot\'{e}G\'{e} Project: A Look Back and a Look Forward},
    year = {2015},
    issue_date = {June 2015},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    volume = {1},
    number = {4},
    url = {https://doi.org/10.1145/2757001.2757003},
    doi = {10.1145/2757001.2757003},
    journal = {AI Matters},
    month = {jun},
    pages = {4–12},
    numpages = {9}
}


@inbook{Bechhofer2009,
	address = {Boston, MA},
	author = {Bechhofer, Sean},
	booktitle = {Encyclopedia of Database Systems},
	doi = {10.1007/978-0-387-39940-9_1073},
	editor = {LIU, LING and {\"O}ZSU, M. TAMER},
	isbn = {978-0-387-39940-9},
	pages = {2008--2009},
	publisher = {Springer US},
	title = {OWL: Web Ontology Language},
	url = {https://doi.org/10.1007/978-0-387-39940-9_1073},
	year = {2009},
	bdsk-url-1 = {https://doi.org/10.1007/978-0-387-39940-9_1073}
}

@misc{lewis2019bart,
      title={BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension}, 
      author={Mike Lewis and Yinhan Liu and Naman Goyal and Marjan Ghazvininejad and Abdelrahman Mohamed and Omer Levy and Ves Stoyanov and Luke Zettlemoyer},
      year={2019},
      eprint={1910.13461},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@book{python,
 author = {Van Rossum, Guido and Drake, Fred L.},
 title = {Python 3 Reference Manual},
 year = {2009},
 isbn = {1441412697},
 publisher = {CreateSpace},
 address = {Scotts Valley, CA}
}

@conference{Kluyver2016jupyter,
Title = {Jupyter Notebooks -- a publishing format for reproducible computational workflows},
Author = {Thomas Kluyver and Benjamin Ragan-Kelley and Fernando P{\'e}rez and Brian Granger and Matthias Bussonnier and Jonathan Frederic and Kyle Kelley and Jessica Hamrick and Jason Grout and Sylvain Corlay and Paul Ivanov and Dami{\'a}n Avila and Safia Abdalla and Carol Willing},
Booktitle = {Positioning and Power in Academic Publishing: Players, Agents and Agendas},
Editor = {F. Loizides and B. Schmidt},
Organization = {IOS Press},
Pages = {87 - 90},
Year = {2016}
}        

@online{huggingface,
title = {Hugging Face},
url = {https://huggingface.co/}
}

@misc{radford2021learning,
      title={Learning Transferable Visual Models From Natural Language Supervision}, 
      author={Alec Radford and Jong Wook Kim and Chris Hallacy and Aditya Ramesh and Gabriel Goh and Sandhini Agarwal and Girish Sastry and Amanda Askell and Pamela Mishkin and Jack Clark and Gretchen Krueger and Ilya Sutskever},
      year={2021},
      eprint={2103.00020},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@online{huggingfaceCLIP,
	title = {Hugging Face CLIP Documentation},
	url = {https://huggingface.co/docs/transformers/model_doc/clip}
}

@misc{dosovitskiy2021image,
	title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale}, 
	author={Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
	year={2021},
	eprint={2010.11929},
	archivePrefix={arXiv},
	primaryClass={cs.CV}
}

@online{dall-e,
	title = {DALL·E: Creating images from text},
	url = {https://openai.com/research/dall-e}
}

@misc{vaswani2017attention,
	title={Attention Is All You Need}, 
	author={Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
	year={2017},
	eprint={1706.03762},
	archivePrefix={arXiv},
	primaryClass={cs.CL}
}

@misc{Radford2019,
  title={Language Models are Unsupervised Multitask Learners},
  author={Alec Radford and Jeff Wu and Rewon Child and David Luan and Dario Amodei and Ilya Sutskever},
  year={2019}
}

@online{owlready2,
	title = {Owlready2},
	url = {https://owlready2.readthedocs.io/en/v0.37/}
}

@online{p5js,
	title = {p5.js},
	url = {https://p5js.org/}
}

@article{ritter,
author = {Ritter, Jack},
year = {1990},
month = {12},
pages = {},
title = {An Efficient Bounding Sphere},
isbn = {9780080507538},
doi = {10.1016/B978-0-08-050753-8.50063-2}
}

@Article{         harris2020array,
 title         = {Array programming with {NumPy}},
 author        = {Charles R. Harris and K. Jarrod Millman and St{\'{e}}fan J.
                 van der Walt and Ralf Gommers and Pauli Virtanen and David
                 Cournapeau and Eric Wieser and Julian Taylor and Sebastian
                 Berg and Nathaniel J. Smith and Robert Kern and Matti Picus
                 and Stephan Hoyer and Marten H. van Kerkwijk and Matthew
                 Brett and Allan Haldane and Jaime Fern{\'{a}}ndez del
                 R{\'{i}}o and Mark Wiebe and Pearu Peterson and Pierre
                 G{\'{e}}rard-Marchant and Kevin Sheppard and Tyler Reddy and
                 Warren Weckesser and Hameer Abbasi and Christoph Gohlke and
                 Travis E. Oliphant},
 year          = {2020},
 month         = sep,
 journal       = {Nature},
 volume        = {585},
 number        = {7825},
 pages         = {357--362},
 doi           = {10.1038/s41586-020-2649-2},
 publisher     = {Springer Science and Business Media {LLC}},
 url           = {https://doi.org/10.1038/s41586-020-2649-2}
}

@online{obj,
title = {Wavefront OBJ File Format Summary},
url = {https://www.fileformat.info/format/wavefrontobj/egff.htm}
}

@article{ravi2020pytorch3d,
    author = {Nikhila Ravi and Jeremy Reizenstein and David Novotny and Taylor Gordon
                  and Wan-Yen Lo and Justin Johnson and Georgia Gkioxari},
    title = {Accelerating 3D Deep Learning with PyTorch3D},
    journal = {arXiv:2007.08501},
    year = {2020}
}

@online{mediumPyTorch3D,
title = {How to render a 3D mesh and convert it to a 2D image using PyTorch3D},
author = {Adele Kuzmiakova},
url = {https://towardsdatascience.com/how-to-render-3d-files-using-pytorch3d-ef9de72483f8}
}

@article{phong,
author = {Phong, Bui Tuong},
title = {Illumination for Computer Generated Pictures},
year = {1975},
issue_date = {June 1975},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {6},
issn = {0001-0782},
url = {https://doi.org/10.1145/360825.360839},
doi = {10.1145/360825.360839},
abstract = {The quality of computer generated images of three-dimensional scenes depends on the shading technique used to paint the objects on the cathode-ray tube screen. The shading algorithm itself depends in part on the method for modeling the object, which also determines the hidden surface algorithm. The various methods of object modeling, shading, and hidden surface removal are thus strongly interconnected. Several shading techniques corresponding to different methods of object modeling and the related hidden surface algorithms are presented here. Human visual perception and the fundamental laws of optics are considered in the development of a shading rule that provides better quality and increased realism in generated images.},
journal = {Commun. ACM},
month = {jun},
pages = {311–317},
numpages = {7},
keywords = {hidden surface removal, shading, computer graphics, graphic display}
}

@online{cgtrader,
title = {CG Trader},
url = {https://www.cgtrader.com/}
}


@Manual{blender,
   title = {Blender - a 3D modelling and rendering package},
   author = {Blender Online Community},
   organization = {Blender Foundation},
   address = {Stichting Blender Foundation, Amsterdam},
   year = {2018},
   url = {http://www.blender.org}
} 

@misc{objectdetectionDT,
	title={Automatic Generation of Digital Twin Based on Scanning and Object Recognition}, 
	author={Markus Sommer, Josip Stjepandić, Sebastian Stobrawa, Moritz von Soden},
	year={2019},
	doi={10.3233/ATDE190174}
}

@article{DTOnto,
author = {Sumit Singh and Essam Shehab and Nigel Higgins and Kevin Fowler and Dylan Reynolds and John A Erkoyuncu and Peter Gadd},
title ={Data management for developing digital twin ontology model},
journal = {Proceedings of the Institution of Mechanical Engineers, Part B: Journal of Engineering Manufacture},
volume = {235},
number = {14},
pages = {2323-2337},
year = {2021},
doi = {10.1177/0954405420978117},
URL = { 
        https://doi.org/10.1177/0954405420978117
    
},
eprint = { 
        https://doi.org/10.1177/0954405420978117    
},
    abstract = { Digital Twin (DT) is the imitation of the real world product, process or system. Digital Twin is the ideal solution for data-driven optimisations in different phases of the product lifecycle. With the rapid growth in DT research, data management for digital twin is a challenging field for both industries and academia. The challenges for DT data management are analysed in this article are data variety, big data \& data mining and DT dynamics. The current research proposes a novel concept of DT ontology model and methodology to address these data management challenges. The DT ontology model captures and models the conceptual knowledge of the DT domain. Using the proposed methodology, such domain knowledge is transformed into a minimum data model structure to map, query and manage databases for DT applications. The proposed research is further validated using a case study based on Condition-Based Monitoring (CBM) DT application. The query formulation around minimum data model structure further shows the effectiveness of the current approach by returning accurate results, along with maintaining semantics and conceptual relationships along DT lifecycle. The method not only provides flexibility to retain knowledge along DT lifecycle but also helps users and developers to design, maintain and query databases effectively for DT applications and systems of different scale and complexities. }
}

@inbook{DTdefinition,
author = {Stark, Rainer and Damerau, Thomas},
year = {2019},
month = {05},
pages = {},
title = {Digital Twin},
isbn = {978-3-642-35950-7},
doi = {10.1007/978-3-642-35950-7_16870-1}
}

@INPROCEEDINGS{7353481,

  author={Maturana, Daniel and Scherer, Sebastian},

  booktitle={2015 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, 

  title={VoxNet: A 3D Convolutional Neural Network for real-time object recognition}, 

  year={2015},

  volume={},

  number={},

  pages={922-928},

  doi={10.1109/IROS.2015.7353481}
}

@InProceedings{ mckinney-proc-scipy-2010,
  author    = { {W}es {M}c{K}inney },
  title     = { {D}ata {S}tructures for {S}tatistical {C}omputing in {P}ython },
  booktitle = { {P}roceedings of the 9th {P}ython in {S}cience {C}onference },
  pages     = { 56 - 61 },
  year      = { 2010 },
  editor    = { {S}t\'efan van der {W}alt and {J}arrod {M}illman },
  doi       = { 10.25080/Majora-92bf1922-00a }
}

@Article{Hunter:2007,
  Author    = {Hunter, J. D.},
  Title     = {Matplotlib: A 2D graphics environment},
  Journal   = {Computing in Science \& Engineering},
  Volume    = {9},
  Number    = {3},
  Pages     = {90--95},
  abstract  = {Matplotlib is a 2D graphics package used for Python for
  application development, interactive scripting, and publication-quality
  image generation across user interfaces and operating systems.},
  publisher = {IEEE COMPUTER SOC},
  doi       = {10.1109/MCSE.2007.55},
  year      = {2007}
}


 
 

